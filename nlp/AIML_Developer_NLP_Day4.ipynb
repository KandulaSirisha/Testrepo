{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c6b3cd73",
   "metadata": {},
   "source": [
    "Create Your Own Spell Checker\n",
    "Objective: Creating a spell checker, correct the incorrect word in the given sentence.\n",
    "Problem Statement: While typing or sending any message to person, we generally make \n",
    "spelling mistakes. Write a script which will correct the misspelled words in a sentence. \n",
    "The input will be a raw string and the output will be a string with the case normalized \n",
    "and the incorrect word corrected.\n",
    "Domain: General\n",
    "Analysis to be done: Words availability in corpus\n",
    "Content: \n",
    "Dataset: None\n",
    "We will be using NLTK’s inbuilt corpora (words, stop words etc.) and no specific dataset.\n",
    "Steps to perform:\n",
    "While there are several approaches to correct spelling , you will use the Levenshtein or \n",
    "Edit distance approach. \n",
    "The approach will be straightforward for correcting a word: \n",
    "▪ If the word is present in a list of valid words, the word is correct.\n",
    "▪ If the word is absent from the valid word list, we will find the correct \n",
    "word, i.e., the word from the valid word list which has the lowest edit \n",
    "distance from the target word.\n",
    "Once you define a function, you will iterate over the terms in the given sentence, \n",
    "correct the words identified as incorrect, and return a joined string with all the terms. \n",
    "To help speed up execution, you won’t be applying the spell check on the stop words\n",
    "and punctuation.\n",
    "Tasks: \n",
    "1. Get a list of valid words in the English language using NLTK’s list of words (Hint: \n",
    "use nltk.download(‘words’) to get the raw list.\n",
    "2. Look at the first 20 words in the list. Is the casing normalized?\n",
    "3. Normalize the casing for all the terms.\n",
    "4. Some duplicates would have been induced, create unique list after normalizing.\n",
    "5. Create a list of stop words which should include: \n",
    "i. Stop words from NLTK\n",
    "ii. All punctuations (Hint: use ‘punctuation’ from string module)\n",
    "iii. Final list should be a combination of these two\n",
    "6. Define a function to get correct a single term\n",
    "• For a given term, find its edit distance with each term in the valid word \n",
    "list. To speed up execution, you can use the first 20,000 entries in the \n",
    "valid word list.\n",
    "• Store the result in a dictionary, the key as the term, and edit distance as \n",
    "value.\n",
    "• Sort the dictionary in ascending order of the values.\n",
    "• Return the first entry in the sorted result (value with minimum edit \n",
    "distance).\n",
    "• Using the function, get the correct word for committee.\n",
    "7. Make a set from the list of valid words, for faster lookup to see if word is in valid \n",
    "list or not.\n",
    "8. Define a function for spelling correction in any given input sentence:\n",
    "1. To tokenize them after making all the terms in lowercase \n",
    "For each term in the tokenized sentence:\n",
    "2. Check if the term is in the list of valid words (valid_words_set).\n",
    "3. If yes, return the word as is.\n",
    "4. If no, get the correct word using get_correct_term function.\n",
    "5. To return the joined string as output.\n",
    "9. Test the function for the input sentence “The new abacos is great”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c52a116b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7402df9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\SIRISHA\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "393ff8a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     C:\\Users\\SIRISHA\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\words.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8d953e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import words, stopwords\n",
    "from string import punctuation\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7fb80243",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 1: Get a list of valid words in the English language\n",
    "valid_words = words.words()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "73aa74c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A', 'a', 'aa', 'aal', 'aalii', 'aam', 'Aani', 'aardvark', 'aardwolf', 'Aaron']\n"
     ]
    }
   ],
   "source": [
    "print(valid_words[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ae53d32b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['botryopterid', 'ridgingly', 'scattered', 'refashionment', 'menacement', 'patriarch', 'monte', 'salicylamide', 'trichogynial', 'uncatholic']\n"
     ]
    }
   ],
   "source": [
    "valid_words_lower = [word.lower() for word in valid_words]\n",
    "valid_words_lower = list(set(valid_words_lower))\n",
    "print(valid_words_lower[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "89118e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english')).union(set(punctuation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c35ca1a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.metrics import edit_distance\n",
    "\n",
    "def get_correct_term(target_word, valid_words):\n",
    "    edit_distances = {}\n",
    "    for word in valid_words:\n",
    "        if word[0] == target_word[0]:\n",
    "            distance = edit_distance(target_word, word)\n",
    "            edit_distances[word] = distance\n",
    "        else:\n",
    "            continue\n",
    "    sorted_edits = sorted(edit_distances.items(), key=lambda x: x[1])\n",
    "    return sorted_edits[0][0] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5734762c",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_words_set = set(valid_words_lower)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2a2bd2aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_spelling(sentence):\n",
    "    tokenized_sentence = nltk.word_tokenize(sentence.lower())\n",
    "    corrected_sentence = []\n",
    "    \n",
    "    for word in tokenized_sentence:\n",
    "        if word in valid_words_set:\n",
    "            corrected_sentence.append(word)\n",
    "        else:\n",
    "            correct_word = get_correct_term(word, valid_words_lower)\n",
    "            corrected_sentence.append(correct_word)\n",
    "    \n",
    "    # Return the joined string as output\n",
    "    return ' '.join(corrected_sentence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "faed6d23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the new abacus is great\n"
     ]
    }
   ],
   "source": [
    "# Task 9: Test the function for the input sentence \"The new abacos is great\"\n",
    "sentence = \"The new abacos is great\"\n",
    "corrected_sentence = correct_spelling(sentence)\n",
    "print(corrected_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b873af9e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
